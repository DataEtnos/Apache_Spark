{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DoC24P6NmAuN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataEtnos/Apache_Spark/blob/main/SparkSQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**SITE PARA CHAVE**\n",
        "\n",
        "**NGROK:** https://ngrok.com\n"
      ],
      "metadata": {
        "id": "Xj6T4Lvoq548"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando o Spark"
      ],
      "metadata": {
        "id": "DoC24P6NmAuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NiqW9-xlnjc",
        "outputId": "e00017b8-ba4d-44c0-a8dc-bb155606046d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (3.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pyspark\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken '2pp0qW25AGqGYK6xftvt4Q4XXLv_JsvPyKtvYupn7z65UHQ5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwxLyrsO_Cj",
        "outputId": "802a243b-7aa4-48ef-b766-abd95e639ef4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBoNwq7KsJGZ",
        "outputId": "8495df3b-88c0-418b-979f-d3557ab37aaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iniciar Sessão Spark"
      ],
      "metadata": {
        "id": "8gIqFurprOZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# ConfigureSparkUI\n",
        "conf = SparkConf().set('spark.ui.port', '4050')\n",
        "sc = SparkContext(conf=conf)\n",
        "sc.stop()\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder                  # Método da classe que constrói a sessão spark\n",
        "      .appName(\"Meu Primeiro App Spark\")  # Nome do App Spark\n",
        "      .getOrCreate())                     # Verifica se há uma sessão ativa, e se não há, cria uma nova sessão\n"
      ],
      "metadata": {
        "id": "vcytxNzMzrnX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "metadata": {
        "id": "tRgaHosSo6PN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nrgrok authtoken 2pp0qW25AGqGYK6xftvt4Q4XXLv_JsvPyKtvYupn7z65UHQ5\n",
        "from flask import Flask\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "  return\"hello , this is your flask app running on google colab with ngrok\"\n",
        "\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(4050)\n",
        "print('link:', public_url)\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyxiAP99PhLB",
        "outputId": "c1f79269-533a-4c22-b5cd-0c69d7eb69a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nrgrok: command not found\n",
            "link: NgrokTunnel: \"https://93b7-34-139-207-112.ngrok-free.app\" -> \"http://localhost:4050\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "WARNING:pyngrok.process.ngrok:t=2024-12-07T15:25:08+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SparkSQL"
      ],
      "metadata": {
        "id": "9mPHkAtuYNO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, TimestampType\n",
        "\n",
        "caminho_csv = \"./base_de_dados.csv\"\n",
        "\n",
        "schema_base_pix = StructType([\n",
        "    StructField('id', IntegerType()),\n",
        "    StructField('valor', DoubleType()),\n",
        "    StructField('parte_debitada_nome', StringType()),\n",
        "    StructField('parte_debitada_conta', StringType()),\n",
        "    StructField('parte_debitada_banco', StringType()),\n",
        "    StructField('parte_creditada_nome', StringType()),\n",
        "    StructField('parte_creditada_conta', StringType()),\n",
        "    StructField('parte_creditada_banco', StringType()),\n",
        "    StructField('chave_pix_tipo', StringType()),\n",
        "    StructField('chave_pix_valor', StringType()),\n",
        "    StructField('data_transacao', TimestampType())\n",
        "])\n",
        "\n",
        "df = spark.read.csv(\n",
        "    path=caminho_csv,\n",
        "    header=True,\n",
        "    sep=\";\",\n",
        "    schema=schema_base_pix,\n",
        "    timestampFormat=\"dd/MM/yyyy HH:mm\"\n",
        ")\n",
        "spark.read.csv(\n",
        "    path=caminho_csv,\n",
        "    header=True,\n",
        "    sep=\";\",\n",
        "    schema=schema_base_pix,\n",
        "    timestampFormat=\"dd/MM/yyyy HH:mm\"\n",
        ").createOrReplaceTempView(\"base_pix\") #criando  uma tabela temporaria"
      ],
      "metadata": {
        "id": "Tww10QvPhTqx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from base_pix limit 3\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM-eqPLQuT23",
        "outputId": "e7c8dd8c-a36f-4da0-ddd2-090d5b38c25c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------------+---------------+-------------------+\n",
            "| id|valor| parte_debitada_nome|parte_debitada_conta|parte_debitada_banco|parte_creditada_nome|parte_creditada_conta|parte_creditada_banco|chave_pix_tipo|chave_pix_valor|     data_transacao|\n",
            "+---+-----+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------------+---------------+-------------------+\n",
            "|  1| 9.93|Dra. Ana Carolina...|            79470453|              Nubank|       Maysa da Cruz|             67162333|                 Itau|           cpf|     8439752610|2022-02-18 13:28:00|\n",
            "|  2|15.38|        Ana Caldeira|            19689668|                Itau|        Evelyn Sales|             60005091|             Bradesco|           cpf|    27145380617|2022-04-08 01:47:00|\n",
            "|  3|57.58|    Arthur Goncalves|            18856899|            Bradesco|          Maria Melo|             13496303|                  BTG|           cpf|    16452937006|2022-07-14 03:18:00|\n",
            "+---+-----+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------------+---------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porém, como saber se a manipulação de dados com Dataframes não é mais rápida que SQL?\n",
        "\n",
        "Para isso vamos propor um group by das duas maneiras e verificar qual é o plano de execução que o spark cria.\n"
      ],
      "metadata": {
        "id": "GYLebBzY2dWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#verificando velocidade de groupby com spark.sql e um dataframe do spark"
      ],
      "metadata": {
        "id": "6cSmaIUitSkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_sql = spark.sql(\"select chave_pix_tipo, count(1) from base_pix group by chave_pix_tipo\")"
      ],
      "metadata": {
        "id": "mz1XUVMb17_y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_dataframe = df.groupBy('chave_pix_tipo').count()"
      ],
      "metadata": {
        "id": "GvnpVoI92Jlx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2_i9k40-lush"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SQL Group\")\n",
        "group_sql.explain()\n",
        "\n",
        "print(\"DataFrame Group\")\n",
        "group_dataframe.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB_IsUNh2St3",
        "outputId": "79b89a9f-da23-4a67-b81b-f2508349ccff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SQL Group\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[chave_pix_tipo#30], functions=[count(1)])\n",
            "   +- Exchange hashpartitioning(chave_pix_tipo#30, 200), ENSURE_REQUIREMENTS, [plan_id=26]\n",
            "      +- HashAggregate(keys=[chave_pix_tipo#30], functions=[partial_count(1)])\n",
            "         +- FileScan csv [chave_pix_tipo#30] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/base_de_dados.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<chave_pix_tipo:string>\n",
            "\n",
            "\n",
            "DataFrame Group\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[chave_pix_tipo#8], functions=[count(1)])\n",
            "   +- Exchange hashpartitioning(chave_pix_tipo#8, 200), ENSURE_REQUIREMENTS, [plan_id=39]\n",
            "      +- HashAggregate(keys=[chave_pix_tipo#8], functions=[partial_count(1)])\n",
            "         +- FileScan csv [chave_pix_tipo#8] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/base_de_dados.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<chave_pix_tipo:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\n",
        "  \"\"\"\n",
        "    select chave_pix_tipo, sum(valor)\n",
        "    from base_pix\n",
        "    group by 1\n",
        "  \"\"\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_1T-ov8mKoP",
        "outputId": "0c908eb5-a75f-475f-df37-18ed9f711baf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+\n",
            "|chave_pix_tipo|        sum(valor)|\n",
            "+--------------+------------------+\n",
            "|       celular|         207778.46|\n",
            "|         email|499009.38000000006|\n",
            "|           cpf| 659513.3499999997|\n",
            "+--------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\n",
        "  \"\"\"\n",
        "    select chave_pix_tipo, round(sum(valor), 2)\n",
        "    from base_pix\n",
        "    group by 1\n",
        "  \"\"\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkFXNzwhmrZb",
        "outputId": "05c3a671-6ae3-4741-cabf-bc7a96798cf5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------+\n",
            "|chave_pix_tipo|round(sum(valor), 2)|\n",
            "+--------------+--------------------+\n",
            "|       celular|           207778.46|\n",
            "|         email|           499009.38|\n",
            "|           cpf|           659513.35|\n",
            "+--------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\n",
        "  \"\"\"\n",
        "    select chave_pix_tipo, round(sum(valor), 2) as sum_valor\n",
        "    from base_pix\n",
        "    group by 1\n",
        "  \"\"\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmmLdhNym0pL",
        "outputId": "0dc1a684-32ad-49d5-a43e-3015086408f9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+---------+\n",
            "|chave_pix_tipo|sum_valor|\n",
            "+--------------+---------+\n",
            "|       celular|207778.46|\n",
            "|         email|499009.38|\n",
            "|           cpf|659513.35|\n",
            "+--------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\n",
        "  \"\"\"\n",
        "    select chave_pix_tipo, count(*) as count\n",
        "    from base_pix\n",
        "    group by 1\n",
        "  \"\"\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPBMgMZ-m3E_",
        "outputId": "7a3f14f7-a9a3-46a8-d25f-019244d6b8be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|chave_pix_tipo|count|\n",
            "+--------------+-----+\n",
            "|       celular|   22|\n",
            "|         email|   29|\n",
            "|           cpf|   49|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sYTJLvr0Sq-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARA AQUI"
      ],
      "metadata": {
        "id": "Bycg9Xv2SrD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\n",
        "    \"\"\"\n",
        "    select * from base_pix\n",
        "    where valor > 1000\n",
        "    \"\"\"\n",
        ").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tufWUiI0Usf",
        "outputId": "c5fbf3b8-9aff-4abc-9f0b-f441cc9567f9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------------+---------------+-------------------+\n",
            "| id|   valor| parte_debitada_nome|parte_debitada_conta|parte_debitada_banco|parte_creditada_nome|parte_creditada_conta|parte_creditada_banco|chave_pix_tipo|chave_pix_valor|     data_transacao|\n",
            "+---+--------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------------+---------------+-------------------+\n",
            "|  4|53705.13|  Ana Julia Caldeira|            22834741|                Itau|   Ana Livia Almeida|             44695116|               Nubank|           cpf|    26590384142|2022-01-15 18:06:00|\n",
            "|  5|25299.69|  Srta. Nicole Pinto|             3715882|              Nubank|Srta. Ana Laura d...|             21409465|               Nubank|           cpf|    73486105280|2022-05-13 11:04:00|\n",
            "|  6| 7165.06|   Gabriela Ferreira|             2243037|              Nubank|       Larissa Souza|             10689552|                 Itau|           cpf|    96845371237|2022-09-11 13:38:00|\n",
            "| 11|33629.97|Sr. Vitor Gabriel...|            67010663|                 BTG|Sra. Lavinia Cald...|             48145941|               Nubank|           cpf|    63542098124|2022-09-12 00:29:00|\n",
            "| 12| 4374.56|      Nathan Peixoto|            22975623|              Nubank|        Diogo da Luz|             30302218|             Bradesco|           cpf|    72908154323|2022-08-07 17:01:00|\n",
            "| 14|67758.87|     Juliana Correia|             4495167|                Itau|    Davi Lucas Porto|             94395923|                  BTG|           cpf|    97804215649|2021-03-24 22:58:00|\n",
            "| 18|49836.72|Ana Carolina Oliv...|            80200942|                Itau|    Stella Fernandes|             31579145|                  BTG|           cpf|    47609381250|2022-07-18 22:46:00|\n",
            "| 20| 9837.22|          Noah Cunha|            84622162|            Bradesco|         Juan Mendes|             97805965|             Bradesco|       celular|    11944547225|2021-06-22 05:39:00|\n",
            "| 27|35859.11|  Ana Carolina Jesus|            56882202|                 BTG|    Kamilly Oliveira|             64189983|                  BTG|       celular|    51918058344|2021-11-27 19:30:00|\n",
            "| 30| 3035.83|Dr. Davi Lucas Ca...|             7706330|                 BTG|Enzo Gabriel Nasc...|             95438570|               Nubank|       celular|    21995027998|2021-01-09 02:17:00|\n",
            "| 31|20875.64|Dr. Joao Gabriel ...|            51847615|                 BTG|        Ana Caldeira|             69556895|             Bradesco|       celular|    84993893778|2022-04-29 10:17:00|\n",
            "| 32| 1508.83|   Sr. Pedro da Mata|            36797731|                 BTG|      Leonardo Porto|             36671966|               Nubank|       celular|    71971735082|2021-10-12 10:04:00|\n",
            "| 34|58083.62|    Giovanna Martins|            64292692|                Itau|       Eduarda Costa|             21654410|             Bradesco|       celular|    11991283574|2021-02-10 06:13:00|\n",
            "| 35| 7944.02|     Clara das Neves|            74962702|                 BTG|       Stella Santos|             70949900|               Nubank|       celular|    41953574945|2022-02-02 14:41:00|\n",
            "| 36|48714.95|Pedro Miguel Azevedo|            16805003|                Itau|    Guilherme Castro|             82754334|                 Itau|       celular|    21962702716|2022-06-07 05:40:00|\n",
            "| 37|19799.16|    Sr. Lucca Barros|            60614524|                Itau|        Samuel Pinto|             72716971|             Bradesco|       celular|    61930570325|2021-02-15 14:13:00|\n",
            "| 46| 5839.39|Dra. Cecilia Cava...|            77097184|                 BTG|    Melissa Monteiro|             61087827|               Nubank|           cpf|    78632019503|2021-06-17 12:09:00|\n",
            "| 47|38219.08|     Livia das Neves|            93530594|                Itau|       Alexia Araujo|             47121539|                  BTG|           cpf|    40152936734|2022-05-23 06:48:00|\n",
            "| 48| 1379.61|       Diogo Barbosa|            43938121|            Bradesco|       Alexia Fogaca|             77922324|               Nubank|           cpf|    37450286190|2022-03-02 06:30:00|\n",
            "| 50| 8745.63|Joao Felipe Oliveira|            59642337|              Nubank|     Lais Nascimento|             70760031|             Bradesco|           cpf|    83051264989|2022-07-17 03:37:00|\n",
            "+---+--------+--------------------+--------------------+--------------------+--------------------+---------------------+---------------------+--------------+---------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\n",
        "    \"\"\"\n",
        "    SELECT *\n",
        "    FROM (\n",
        "        SELECT\n",
        "            parte_creditada_banco,\n",
        "            valor,\n",
        "            ROW_NUMBER() OVER (PARTITION BY parte_creditada_banco ORDER BY valor DESC) AS row_number\n",
        "        FROM base_pix\n",
        "    ) subquery\n",
        "    WHERE row_number in (1,2)\n",
        "    \"\"\"\n",
        ").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcBybrlenM0e",
        "outputId": "8b46c8aa-e55a-47a6-ecbf-73573702c9a9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------+----------+\n",
            "|parte_creditada_banco|   valor|row_number|\n",
            "+---------------------+--------+----------+\n",
            "|                  BTG|95977.62|         1|\n",
            "|                  BTG|80083.34|         2|\n",
            "|             Bradesco|81977.98|         1|\n",
            "|             Bradesco|58083.62|         2|\n",
            "|                 Itau|94586.45|         1|\n",
            "|                 Itau| 78559.4|         2|\n",
            "|               Nubank|94736.79|         1|\n",
            "|               Nubank|60139.23|         2|\n",
            "+---------------------+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CTE stands for common table expression. A CTE allows you to define a temporary named result set that available temporarily in the execution scope of a statement such as SELECT, INSERT, UPDATE, DELETE, or MERGE"
      ],
      "metadata": {
        "id": "dpfsHISapCwS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0E37n56ybULQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\n",
        "  \"\"\"\n",
        "  with base_pix_row_number as(\n",
        "    select\n",
        "      parte_creditada_banco,\n",
        "      data_transacao,\n",
        "      row_number() over (partition by parte_creditada_banco order by data_transacao desc) as row_number\n",
        "    from base_pix\n",
        "  ) select\n",
        "      parte_creditada_banco,\n",
        "      data_transacao\n",
        "    from base_pix_row_number\n",
        "    where row_number = 1\n",
        "    order by data_transacao desc\n",
        "  \"\"\"\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu8jGKlKoJoq",
        "outputId": "ba1a565e-19d4-4d1e-89ca-77b78468faeb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------------+\n",
            "|parte_creditada_banco|     data_transacao|\n",
            "+---------------------+-------------------+\n",
            "|                 Itau|2022-12-15 01:29:00|\n",
            "|                  BTG|2022-12-08 23:47:00|\n",
            "|               Nubank|2022-11-19 19:25:00|\n",
            "|             Bradesco|2022-08-07 17:01:00|\n",
            "+---------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porém, não precisa ficar limitado somente a execução de queries SQL.\n",
        "\n",
        "Podemos pegar o resultado de uma query e retorná-la para um DataFrame!"
      ],
      "metadata": {
        "id": "lkSb46FNp3Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_window = spark.sql(\n",
        "  \"\"\"\n",
        "  with base_pix_row_number as(\n",
        "    select\n",
        "      parte_creditada_banco,\n",
        "      data_transacao,\n",
        "      row_number() over (partition by parte_creditada_banco order by data_transacao desc) as row_number\n",
        "    from base_pix\n",
        "  ) select\n",
        "      parte_creditada_banco,\n",
        "      data_transacao\n",
        "    from base_pix_row_number\n",
        "    where row_number = 1\n",
        "    order by data_transacao desc\n",
        "  \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "h5vx27b8pxb5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_window.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JosM2a0Bp1Cq",
        "outputId": "6cd510e2-386c-46db-ec46-b69732502533"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------------+\n",
            "|parte_creditada_banco|     data_transacao|\n",
            "+---------------------+-------------------+\n",
            "|                 Itau|2022-12-15 01:29:00|\n",
            "|                  BTG|2022-12-08 23:47:00|\n",
            "|               Nubank|2022-11-19 19:25:00|\n",
            "|             Bradesco|2022-08-07 17:01:00|\n",
            "+---------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mWTbDdo3S8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This opens up the true power of Spark. We can treat selectExpr as a simple way to build up\n",
        "complex expressions that create new DataFrames. In fact, we can add any valid non-aggregating\n",
        "SQL statement, and as long as the columns resolve, it will be valid!"
      ],
      "metadata": {
        "id": "G7DBXmibq97j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "oq-ec7scstUg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.selectExpr(\n",
        "    \"date(data_transacao) as date_data_transacao\",\n",
        "    \"valor\"\n",
        ").groupBy('date_data_transacao').count().orderBy(col('count').desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eri84Mkgq1fK",
        "outputId": "a792bfd2-3344-4c37-8f67-ab3e48694b19"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----+\n",
            "|date_data_transacao|count|\n",
            "+-------------------+-----+\n",
            "|         2022-02-26|    2|\n",
            "|         2022-03-02|    2|\n",
            "|         2021-06-22|    1|\n",
            "|         2022-11-29|    1|\n",
            "|         2021-07-20|    1|\n",
            "|         2021-02-15|    1|\n",
            "|         2021-03-22|    1|\n",
            "|         2022-02-16|    1|\n",
            "|         2021-04-25|    1|\n",
            "|         2021-03-07|    1|\n",
            "|         2022-01-15|    1|\n",
            "|         2022-01-09|    1|\n",
            "|         2022-05-23|    1|\n",
            "|         2022-02-01|    1|\n",
            "|         2021-07-11|    1|\n",
            "|         2022-04-12|    1|\n",
            "|         2022-06-05|    1|\n",
            "|         2021-09-06|    1|\n",
            "|         2021-06-20|    1|\n",
            "|         2021-12-14|    1|\n",
            "+-------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício\n",
        "1. Vimos que há dois dias em que houve duas transações pix. Descubra são os ids dessas transações.\n",
        "\n",
        "2. Vimos que há dois dias em que houve duas transações pix. Descubra quais chaves pix foram utilizadas para realizar as transações."
      ],
      "metadata": {
        "id": "y-ob-JQ_tPvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_datas = spark.sql(\n",
        "  \"\"\"\n",
        "  select\n",
        "    date(data_transacao) as date_data_transacao\n",
        "  from base_pix\n",
        "  group by 1\n",
        "  having count(*) > 1\n",
        "  \"\"\"\n",
        ").collect()[0][0]\n",
        "lista_datas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbKknPUysbcK",
        "outputId": "99a29643-c7cc-43af-e729-054281f3af00"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.date(2022, 2, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}